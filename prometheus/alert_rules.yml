# Alert Rules for Smart System Health Monitor
# These rules implement intelligent alerting with predictive capabilities

groups:
  - name: system_health_alerts
    interval: 15s
    rules:
      # ============================================================
      # COMPOSITE HEALTH SCORE ALERT
      # Triggers when overall system health degrades
      # ============================================================
      - alert: HighSystemHealthScore
        expr: |
          (
            (100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) * 0.4 +
            ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100) * 0.4 +
            ((node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} - node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*|overlay"}) / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} * 100) * 0.2
          ) > 75
        for: 2m
        labels:
          severity: warning
          category: health_score
        annotations:
          summary: "System health score is high (instance {{ $labels.instance }})"
          description: "Composite health score is {{ $value | humanize }}% (threshold: 75%). This indicates overall system stress across CPU, memory, and disk resources."
          impact: "System performance may be degraded. Consider investigating resource usage."
          
      - alert: CriticalSystemHealthScore
        expr: |
          (
            (100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) * 0.4 +
            ((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100) * 0.4 +
            ((node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} - node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*|overlay"}) / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} * 100) * 0.2
          ) > 90
        for: 1m
        labels:
          severity: critical
          category: health_score
        annotations:
          summary: "CRITICAL: System health score is very high (instance {{ $labels.instance }})"
          description: "Composite health score is {{ $value | humanize }}% (threshold: 90%). System is under severe stress!"
          impact: "System may become unresponsive. Immediate action required."

      # ============================================================
      # PREDICTIVE CPU OVERLOAD ALERT
      # Uses linear prediction to forecast CPU saturation 10 minutes ahead
      # ============================================================
      - alert: PredictedCPUOverload
        expr: |
          predict_linear(
            avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))[10m:15s], 
            600
          ) < 0.05
        for: 2m
        labels:
          severity: warning
          category: predictive
        annotations:
          summary: "CPU overload predicted in 10 minutes (instance {{ $labels.instance }})"
          description: "Based on current trends, CPU idle time is predicted to drop to {{ $value | humanize }}% in 10 minutes. Current idle: {{ query \"avg by(instance) (rate(node_cpu_seconds_total{mode='idle'}[5m])) * 100\" | first | value | humanize }}%"
          impact: "System may become CPU-bound soon. Consider reducing load or scaling resources."
          recommendation: "Investigate high CPU processes using 'top' or 'htop'"

      # ============================================================
      # MEMORY EXHAUSTION PREDICTION
      # Detects continuous memory growth and predicts exhaustion
      # ============================================================
      - alert: MemoryGrowthDetected
        expr: |
          deriv(node_memory_MemAvailable_bytes[5m]) < -10485760
        for: 5m
        labels:
          severity: warning
          category: predictive
        annotations:
          summary: "Continuous memory consumption detected (instance {{ $labels.instance }})"
          description: "Available memory is decreasing at {{ $value | humanize }}B/s over the last 5 minutes. This trend may lead to memory exhaustion."
          current_available: "{{ query \"node_memory_MemAvailable_bytes\" | first | value | humanize }}B"
          impact: "System may run out of memory if trend continues."
          
      - alert: PredictedMemoryExhaustion
        expr: |
          predict_linear(node_memory_MemAvailable_bytes[10m], 600) < 1073741824
        for: 2m
        labels:
          severity: critical
          category: predictive
        annotations:
          summary: "Memory exhaustion predicted in 10 minutes (instance {{ $labels.instance }})"
          description: "Based on current trends, available memory will drop to {{ $value | humanize }}B (< 1GB) in 10 minutes."
          current_available: "{{ query \"node_memory_MemAvailable_bytes\" | first | value | humanize }}B"
          impact: "System may start swapping or OOM killer may activate."
          recommendation: "Identify memory-hungry processes and consider terminating or restarting services"

      # ============================================================
      # CURRENT RESOURCE ALERTS
      # Traditional threshold-based alerts for immediate issues
      # ============================================================
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 3m
        labels:
          severity: warning
          category: cpu
        annotations:
          summary: "High CPU usage detected (instance {{ $labels.instance }})"
          description: "CPU usage is {{ $value | humanize }}% (threshold: 85%)"
          
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 3m
        labels:
          severity: warning
          category: memory
        annotations:
          summary: "High memory usage detected (instance {{ $labels.instance }})"
          description: "Memory usage is {{ $value | humanize }}% (threshold: 85%)"
          available: "{{ query \"node_memory_MemAvailable_bytes\" | first | value | humanize }}B available"

      - alert: DiskSpaceCritical
        expr: |
          (node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} - node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*|overlay"}) 
          / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.*|overlay"} * 100 > 85
        for: 5m
        labels:
          severity: critical
          category: disk
        annotations:
          summary: "Disk space critical on {{ $labels.mountpoint }} (instance {{ $labels.instance }})"
          description: "Disk usage is {{ $value | humanize }}% on {{ $labels.mountpoint }} (threshold: 85%)"
          available: "{{ query \"node_filesystem_avail_bytes{mountpoint='\" $labels.mountpoint \"'}\" | first | value | humanize }}B available"
          recommendation: "Clean up old files, logs, or consider expanding storage"

      # ============================================================
      # SYSTEM STABILITY ALERTS
      # ============================================================
      - alert: HighLoadAverage
        expr: |
          node_load15 / count(node_cpu_seconds_total{mode="idle"}) > 1.5
        for: 5m
        labels:
          severity: warning
          category: load
        annotations:
          summary: "High system load average (instance {{ $labels.instance }})"
          description: "15-minute load average is {{ $value | humanize }} (threshold: 1.5x CPU cores)"
          
      - alert: TooManyProcesses
        expr: |
          node_processes_state{state="running"} > 500
        for: 5m
        labels:
          severity: warning
          category: processes
        annotations:
          summary: "Too many running processes (instance {{ $labels.instance }})"
          description: "{{ $value }} processes are running (threshold: 500)"

      # ============================================================
      # MONITORING HEALTH
      # Ensures the monitoring stack itself is healthy
      # ============================================================
      - alert: NodeExporterDown
        expr: up{job="node-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          category: monitoring
        annotations:
          summary: "Node Exporter is down (instance {{ $labels.instance }})"
          description: "Node Exporter has been down for more than 1 minute. System metrics are not being collected!"
          impact: "Cannot monitor system health. Alerts may not fire."
          
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          category: monitoring
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus server is not responding. Monitoring is offline!"
